{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import Sequential\n",
    "from nltk.tokenize import word_tokenize \n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_nltk = stopwords.words(\"english\")\n",
    "stop_updated = stop_nltk + list(punctuation)\n",
    "lemm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  clean_txt(sent):\n",
    "    tokens = word_tokenize(sent.lower().replace('[^a-z ]',' '))\n",
    "    stemmed = [lemm.lemmatize(term) for term in tokens \n",
    "               if term not in stop_updated and len(term) > 2] \n",
    "    res = \" \".join(stemmed)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cleaned_review'] = train.comment_text.apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "x=train['cleaned_review'].values\n",
    "y=train[labels].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=30000,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(list(x))\n",
    "tokenized_train = tokenizer.texts_to_sequences(x)\n",
    "x_t = pad_sequences(tokenized_train, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving Tokenizer\n",
    "\n",
    "with open('tokenizer.pickle','wb') as handle:\n",
    "    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen, ))\n",
    "embed_size = 128\n",
    "x = Embedding(max_features, embed_size)(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = LSTM(60, return_sequences=True,name='lstm_layer')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = GlobalMaxPool1D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(0.2)(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 200, 128)          3840000   \n",
      "_________________________________________________________________\n",
      "lstm_layer (LSTM)            (None, 200, 60)           45360     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                3050      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 3,888,716\n",
      "Trainable params: 3,888,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "\n",
    "filepath='wts.h5'\n",
    "checkpoint=ModelCheckpoint(filepath,monitor='val_accuracy',verbose=1,save_best_only=True,mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Fitting\n",
    "\n",
    "model.fit(x_t,y, batch_size=30, epochs=1, validation_split=0.33, verbose=0, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model with unseen comments\n",
    "\n",
    "test_comments = [\"Never trust Udemy. It is the most pathetic, unworthy and untrustful site.\",\"When seeing all over the experience with Udemy is too bad and I never recommend anyone to go for udemy. Type of YouTube channels are better than udemy.. At least you can save your money.\",\"Many of my coworkers choose to use Udemy for continuing education. I feel it has the best selection, training and curriculum vs others I have tried. Yes, the courses may be longer than others, but they're more detailed.\",\"This bar sucks plain and simple. Dominated by hipster retro people that can not be talked to unless you know know Morrissey's new album. Pabst always a great price shit bartenders who will ignore you and make drinks like they know what they are doing. This place is great for any 20 something year old trying to fit in haha garbage place. Oh do not forget the sexist 5 dollar make charge lol get fucked\",\"An extremely helpful and informative course, especially in conjuction with multi-modal training. Training materials were well organized and provided good case studies. Instructor was extremely professional and pleasant to learn from. Dawn did an exceptional job presenting the material. She set up by explaining what she was going to teach us, summarized, and proceeded to teach, providing relevant real life examples. She found out what we handled and catered examples to us to make the course meaningful. I am a CHMM and have taken many similar courses - this was very well done, which I attribute primarily to the instructor and secondarily to the quality materials.\"]\n",
    "\n",
    "test_df = pd.DataFrame(data=test_comments, columns=['Test Comments'])\n",
    "\n",
    "test_df['Clean_test_comm'] = test_df['Test Comments'].apply(clean_txt)\n",
    "\n",
    "test=test_df['Clean_test_comm'].values\n",
    "\n",
    "tokenized_test = tokenizer.texts_to_sequences(list(test))\n",
    "\n",
    "xtest = pad_sequences(tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.24631524e-01, 1.28108263e-03, 8.85643363e-02, 5.08612394e-03,\n",
       "        2.13645548e-01, 1.09324753e-02],\n",
       "       [3.02195549e-05, 0.00000000e+00, 3.63588333e-06, 1.19209290e-07,\n",
       "        2.29477882e-06, 1.19209290e-07],\n",
       "       [1.72734261e-04, 0.00000000e+00, 1.82688236e-05, 4.76837158e-07,\n",
       "        1.15036964e-05, 6.25848770e-07],\n",
       "       [6.60809457e-01, 5.06237149e-03, 5.02703011e-01, 2.50238180e-03,\n",
       "        2.72275239e-01, 1.26154125e-02],\n",
       "       [3.25143337e-04, 8.94069672e-08, 3.43322754e-05, 1.01327896e-06,\n",
       "        2.12318319e-05, 2.63981246e-06]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred=model.predict(xtest)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clean_test_comm</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never trust udemy pathetic unworthy untrustful...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seeing experience udemy bad never recommend an...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many coworkers choose use udemy continuing edu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bar suck plain simple dominated hipster retro ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>extremely helpful informative course especiall...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Clean_test_comm  toxic  severe_toxic  \\\n",
       "0  never trust udemy pathetic unworthy untrustful...    1.0           0.0   \n",
       "1  seeing experience udemy bad never recommend an...    0.0           0.0   \n",
       "2  many coworkers choose use udemy continuing edu...    0.0           0.0   \n",
       "3  bar suck plain simple dominated hipster retro ...    1.0           0.0   \n",
       "4  extremely helpful informative course especiall...    0.0           0.0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0      0.0     0.0     0.0            0.0  \n",
       "1      0.0     0.0     0.0            0.0  \n",
       "2      0.0     0.0     0.0            0.0  \n",
       "3      1.0     0.0     0.0            0.0  \n",
       "4      0.0     0.0     0.0            0.0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_fin = pd.concat([test_df, pd.DataFrame(data=np.round(ypred), columns=labels)], axis=1)\n",
    "test_df_fin.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
